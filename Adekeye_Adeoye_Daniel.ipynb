{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOdUGQNLPMtQ5FMyygRAwY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdekeyeAdeoyeDaniel/Altschool_2/blob/main/Adekeye_Adeoye_Daniel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exam Project for the Karatu Session**\n",
        "\n",
        "Instructions:\n",
        "\n",
        "●\tYou will be provided with a dataset in CSV format. [The link to the dataset](https://drive.google.com/file/d/1g4FHOllqK1ZyJc2pweIlzhw5Dnn_kFsu/view?usp=sharing)\n",
        "\n",
        "●\tYour tasks are to write Python functions that accomplish the following:\n"
      ],
      "metadata": {
        "id": "E3InmKlcLOkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "PebRMK1rIoQX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tRead the dataset into a pandas Data Frame. [***Extra marks if you handle exceptions gracefully and print meaningful error messages.***]\n"
      ],
      "metadata": {
        "id": "l7Blv9lPOIZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_open():\n",
        "    \"\"\"\n",
        "    This function opens a CSV file and returns a Pandas DataFrame.\n",
        "\n",
        "    \"\"\"\n",
        "    file_name_path = input ('Enter the dataset name or path: ') #requests file name or path from user\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "          titanic_csv = pd.read_csv(file_name_path)\n",
        "          print(\"Dataset loaded successfully!\")  # Print confirmation of successful loading\n",
        "          return titanic_csv\n",
        "          break\n",
        "\n",
        "        except FileNotFoundError:\n",
        "          # This exception is raised if the file specified by the user cannot be found.\n",
        "          print(\"File not found. Please check the file name or path and try again.\")\n",
        "\n",
        "        except pd.errors.EmptyDataError:\n",
        "          # This exception is raised if the file exists but is empty, meaning it has no data to load.\n",
        "          print(\"The file is empty. Please provide a valid dataset.\")\n",
        "\n",
        "        except pd.errors.ParserError:\n",
        "          # This exception is raised if there is an issue with parsing the file.\n",
        "          print(\"Error parsing the file. Ensure it is a valid CSV.\")\n"
      ],
      "metadata": {
        "id": "2CUOVdd0IsqK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Sum the missing values for each column.** [Ensure the function returns a pandas Series that lists the missing values for each column]\n"
      ],
      "metadata": {
        "id": "m_Y63kMaOsig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_missing_values(titanic_csv):\n",
        "    \"\"\"\n",
        "    This function returns a Pandas Series listing the number of missing values for each column.\n",
        "    \"\"\"\n",
        "    missing_values = titanic_csv.isna().sum() #calculates the number of missing (NaN) values for each column\n",
        "\n",
        "    return missing_values"
      ],
      "metadata": {
        "id": "ZsUWspnfI1CR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tCheck for duplicates in each column.** [Ensure the function returns a dictionary with column names and boolean values indicating the presence of duplicates.]\n"
      ],
      "metadata": {
        "id": "2SJ-S-LTPSse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_check(titanic_csv):\n",
        "  \"\"\"\n",
        "  This function checks for duplicates in each column and returns a dictionary with column names and boolean values indicating the presence of duplicates.\n",
        "  \"\"\"\n",
        "  cols = titanic_csv.columns #create a list of all\n",
        "\n",
        "  duplicate_dict = {} #create an empty dictionary\n",
        "\n",
        "  for col in cols: #iterate through each column\n",
        "    duplicate_dict[col] = titanic_csv.duplicated(subset=[col], keep=False).tolist() #By setting keep on False, all duplicates are True.\n",
        "\n",
        "  return duplicate_dict\n"
      ],
      "metadata": {
        "id": "_AcrQ6nUI4Km"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative 1\n"
      ],
      "metadata": {
        "id": "kI26tRT1UuKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_check(df):\n",
        "  \"\"\"\n",
        "  This function checks for duplicates in each column and returns a dictionary with column names and boolean values indicating the presence of duplicates.\n",
        "  \"\"\"\n",
        "  cols = df.columns #create a list of all\n",
        "\n",
        "  duplicate_dict = {} #create an empty dictionary\n",
        "\n",
        "  for col in cols: #iterate through each column\n",
        "    duplicate_dict[col] = df.duplicated(subset=[col], keep=False).tolist() #By setting keep on False, all duplicates are True.\n",
        "\n",
        "  return duplicate_dict\n"
      ],
      "metadata": {
        "id": "g1YDbk1DUh2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative 2, using dictionary comprehension\n"
      ],
      "metadata": {
        "id": "qNAulKdHTppf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def duplicate_check():\n",
        "  \"\"\"\n",
        "  This function checks for duplicates in each column and returns a dictionary with column names and boolean values indicating the presence of duplicates.\n",
        "  By setting keep on False, all duplicates are True.\n",
        "\n",
        "  \"\"\"\n",
        "  return {col: df[col].duplicated(keep=False).tolist() for col in df.columns}\n"
      ],
      "metadata": {
        "id": "-hUjvelWTpU7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset**"
      ],
      "metadata": {
        "id": "NgU4R6G5P8Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = file_open()\n",
        "\n",
        "# Calculate and print the missing values\n",
        "missing_values_summary = sum_missing_values(df)\n",
        "print(\"Missing Values Summary:\")\n",
        "print(missing_values_summary)\n",
        "\n",
        "# Check and print duplicates\n",
        "duplicates_summary = duplicate_check(df)\n",
        "print(\"Duplicates Check:\")\n",
        "print(duplicates_summary)"
      ],
      "metadata": {
        "id": "l3XOZqEHI60x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}